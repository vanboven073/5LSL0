{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_dataloader import Noisy_MNIST\n",
    "from Fast_MRI_dataloader import Fast_MRI\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.fft import fft2, fftshift, ifft2, ifftshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% dataloader for the Fast MRI dataset\n",
    "def create_dataloaders_mri(data_loc, batch_size):\n",
    "    dataset_train = Fast_MRI(\"train\", data_loc)\n",
    "    dataset_test  = Fast_MRI(\"test\" , data_loc)\n",
    "    \n",
    "    Fast_MRI_train_loader =  DataLoader(dataset_train, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    Fast_MRI_test_loader  =  DataLoader(dataset_test , batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    \n",
    "    return Fast_MRI_train_loader, Fast_MRI_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bram\n",
    "#data_loc = 'D://5LSL0-Datasets//Fast_MRI_Knee' #change the datalocation to something that works for you\n",
    "#Amin \n",
    "data_loc = 'C:/Users/amin2/Documents/School/5LSL0ML/5LSL0/data/Fast_MRI_Knee'\n",
    "\n",
    "\n",
    "# define parameters\n",
    "batch_size = 8\n",
    "\n",
    "train_loader, test_loader = create_dataloaders_mri(data_loc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self, ).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to achieve Full k-space\n",
    "def get_k_space(inputs):\n",
    "    k_space = fftshift(fft2(inputs))\n",
    "    return k_space\n",
    "\n",
    "# Define function to achieve Partial k-space from Full k-space and Mask\n",
    "def get_partial_k_space(input,M):\n",
    "    return  torch.mul(input, M)\n",
    "\n",
    "def get_accelerate_MRI(inputs):\n",
    "    return ifft2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam( model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "#unfolding steps\n",
    "num_iterations = 5\n",
    "prox_operator = nn.ModuleList([ConvNet() for _ in range(num_iterations)])\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/10]:  71%|███████▏  | 67/94 [05:51<02:21,  5.24s/it, loss=0.151]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iterations):\n\u001b[1;32m---> 17\u001b[0m     x_t \u001b[39m=\u001b[39m model(x_t)\n\u001b[0;32m     18\u001b[0m     F_x \u001b[39m=\u001b[39m get_k_space(x_t)\n\u001b[0;32m     20\u001b[0m     k_space_y \u001b[39m=\u001b[39m get_k_space(acc_mri)\n",
      "File \u001b[1;32mc:\\Users\\amin2\\anaconda3\\envs\\MachineLearningSignalProcessing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m     14\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m---> 15\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu1(x)\n\u001b[0;32m     16\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[0;32m     17\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeconv2(x)\n",
      "File \u001b[1;32mc:\\Users\\amin2\\anaconda3\\envs\\MachineLearningSignalProcessing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amin2\\anaconda3\\envs\\MachineLearningSignalProcessing\\lib\\site-packages\\torch\\nn\\modules\\activation.py:777\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 777\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\amin2\\anaconda3\\envs\\MachineLearningSignalProcessing\\lib\\site-packages\\torch\\nn\\functional.py:1632\u001b[0m, in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu_(\u001b[39minput\u001b[39m, negative_slope)\n\u001b[0;32m   1631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1632\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[0;32m   1633\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader)\n",
    "    loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "    for i,(kspace, M, gt) in enumerate(loop):\n",
    "        gt_label = gt.unsqueeze(1)\n",
    "        kspace_input = kspace.unsqueeze(1)\n",
    "        acc_mri = torch.abs(ifft2(kspace_input))\n",
    "        x_t = acc_mri\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for iter in range(num_iterations):\n",
    "            x_t = prox_operator[iter](x_t)\n",
    "            F_x = get_k_space(x_t)\n",
    "\n",
    "            k_space_y = get_k_space(acc_mri)\n",
    "            F_x = torch.squeeze(F_x, dim=1) \n",
    "            k_space_y = torch.squeeze(k_space_y, dim=1) \n",
    "            z = F_x - mu * get_partial_k_space(F_x, M) + mu * get_partial_k_space(k_space_y, M)\n",
    "            z = torch.unsqueeze(z, dim=1) \n",
    "            x_t = torch.abs(get_accelerate_MRI(z))\n",
    "            loss = criterion(x_t, gt_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        count+=1\n",
    "        train_loss += loss.item() #* kspace_input.size(0)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    count_test = 0\n",
    "    test_loss = 0\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "       loop = tqdm(test_loader)\n",
    "       for i,(kspace_t, M_t, gt_t) in enumerate(loop):\n",
    "            gt_label_t = gt_t.unsqueeze(1)\n",
    "            kspace_input_t = kspace_t.unsqueeze(1)\n",
    "            acc_mri_t = torch.abs(ifft2(kspace_input_t))\n",
    "            x_t = acc_mri_t\n",
    "\n",
    "            for iter in range(num_iterations):\n",
    "                x_t = model(x_t)\n",
    "                F_x = get_k_space(x_t)\n",
    "\n",
    "                k_space_y = get_k_space(acc_mri_t)\n",
    "                F_x = torch.squeeze(F_x, dim=1) \n",
    "                k_space_y = torch.squeeze(k_space_y, dim=1) \n",
    "                z = F_x - mu * get_partial_k_space(F_x, M) + mu * get_partial_k_space(k_space_y, M)\n",
    "                z = torch.unsqueeze(z, dim=1) \n",
    "                x_t = torch.abs(get_accelerate_MRI(z))\n",
    "            loss = criterion(x_t, gt_label_t)\n",
    "            count_test +=1\n",
    "            test_loss += loss.item() #* kspace_input.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= count\n",
    "    test_loss /= count_test\n",
    "\n",
    "    # train_losses.append(train_loss)\n",
    "    # test_losses.append(test_loss)\n",
    "\n",
    "    # Print epoch-wise loss\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "# Save the trained model   \n",
    "torch.save(model.state_dict(), 'Ex6_trained.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningSignalProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
