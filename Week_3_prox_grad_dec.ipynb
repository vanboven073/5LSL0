{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amin2\\anaconda3\\envs\\MachineLearningSignalProcessing\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MNIST_dataloader import Noisy_MNIST\n",
    "from Fast_MRI_dataloader import Fast_MRI\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.fft import fft2, fftshift, ifft2, ifftshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% dataloader for the Fast MRI dataset\n",
    "def create_dataloaders_mri(data_loc, batch_size):\n",
    "    dataset_train = Fast_MRI(\"train\", data_loc)\n",
    "    dataset_test  = Fast_MRI(\"test\" , data_loc)\n",
    "    \n",
    "    Fast_MRI_train_loader =  DataLoader(dataset_train, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    Fast_MRI_test_loader  =  DataLoader(dataset_test , batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    \n",
    "    return Fast_MRI_train_loader, Fast_MRI_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bram\n",
    "#data_loc = 'D://5LSL0-Datasets//Fast_MRI_Knee' #change the datalocation to something that works for you\n",
    "#Amin \n",
    "data_loc = 'C:/Users/amin2/Documents/School/5LSL0ML/5LSL0/data/Fast_MRI_Knee'\n",
    "\n",
    "\n",
    "# define parameters\n",
    "batch_size = 8\n",
    "\n",
    "train_loader, test_loader = create_dataloaders_mri(data_loc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self, ).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to achieve Full k-space\n",
    "def get_k_space(inputs):\n",
    "    # get the k-space\n",
    "    i = 0\n",
    "    k_space = []\n",
    "    for img in inputs:\n",
    "        k_space[i] = fftshift(fft2(img))\n",
    "        i+=1\n",
    "    return k_space\n",
    "\n",
    "# Define function to achieve Partial k-space from Full k-space and Mask\n",
    "def get_partial_k_space(input,M):\n",
    "    return  torch.mul(input, M)\n",
    "\n",
    "def get_accelerate_MRI(inputs):\n",
    "    return ifft2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "num_iterations = 5\n",
    "mu = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader)\n",
    "    loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "    for i,(kspace, M, gt) in enumerate(loop):\n",
    "        gt_label = gt.unsqueeze(1)\n",
    "        kspace_input = kspace.unsqueeze(1)\n",
    "        for iter in num_iterations:\n",
    "            # get accelerated MRI image from partial k-space\n",
    "            acc_mri = torch.abs(ifft2(kspace_input))\n",
    "            optimizer.zero_grad()\n",
    "            z = get_k_space(outputs)\n",
    "            z = np.identity() - mu * np.dot(np.transpose(z),z)\n",
    "            outputs = model(acc_mri)\n",
    "\n",
    "            loss = criterion(outputs, gt_label)\n",
    "            loss.backward()\n",
    "        count+=1\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() #* kspace_input.size(0)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    count_test = 0\n",
    "    test_loss = 0\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "       loop = tqdm(test_loader)\n",
    "       for i,(kspace_t, M_t, gt_t) in enumerate(loop):\n",
    "            gt_label_t = gt_t.unsqueeze(1)\n",
    "            kspace_input_t = kspace_t.unsqueeze(1)\n",
    "\n",
    "            # get accelerated MRI image from partial k-space\n",
    "            acc_mri_t = torch.abs(ifft2(kspace_input_t))\n",
    "\n",
    "            outputs = model(acc_mri_t)\n",
    "            count_test +=1\n",
    "            loss = criterion(outputs, gt_label_t)\n",
    "            test_loss += loss.item()# * kspace_input_t.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= count\n",
    "    test_loss /= count_test\n",
    "\n",
    "    # train_losses.append(train_loss)\n",
    "    # test_losses.append(test_loss)\n",
    "\n",
    "    # Print epoch-wise loss\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "# Save the trained model   \n",
    "torch.save(model.state_dict(), 'Ex6_trained.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningSignalProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
