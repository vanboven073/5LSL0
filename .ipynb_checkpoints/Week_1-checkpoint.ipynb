{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_dataloader import Noisy_MNIST\n",
    "from Fast_MRI_dataloader import Fast_MRI\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bram\n",
    "#data_loc = 'D://5LSL0-Datasets' #change the datalocation to something that works for you\n",
    "#Amin\n",
    "data_loc = 'C://Gebruikers/amin2/Documenten/School/5LSL0 - MLSignal/5LSL0/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% dataloader for the Fast MRI dataset\n",
    "def create_dataloaders_mri(data_loc, batch_size):\n",
    "    dataset_train = Fast_MRI(\"train\", data_loc)\n",
    "    dataset_test  = Fast_MRI(\"test\" , data_loc)\n",
    "    \n",
    "    Fast_MRI_train_loader =  DataLoader(dataset_train, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    Fast_MRI_test_loader  =  DataLoader(dataset_test , batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    \n",
    "    return Fast_MRI_train_loader, Fast_MRI_test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% dataloader for the Noisy MNIST dataset\n",
    "def create_dataloaders_noisy_mnist(data_loc, batch_size):\n",
    "    Noisy_MNIST_train = Noisy_MNIST(\"train\", data_loc)\n",
    "    Noisy_MNIST_test  = Noisy_MNIST(\"test\" , data_loc)\n",
    "    \n",
    "    Noisy_MNIST_train_loader =  DataLoader(Noisy_MNIST_train, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    Noisy_MNIST_test_loader  =  DataLoader(Noisy_MNIST_test , batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    \n",
    "    return Noisy_MNIST_train_loader, Noisy_MNIST_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Week 1\n",
    "# 1A create python function for denoising MNIST\n",
    "# ISTA function for denoising\n",
    "def ista_denoise(batch, step_size, num_iterations, lambda_val):\n",
    "    #iterate over all images in batch\n",
    "    batch_size, height, width = batch.shape\n",
    "    denoised_list = []\n",
    "    for img in batch:\n",
    "        #signal estimator\n",
    "        x = np.zeros((height, width))\n",
    "        #sensing matrix\n",
    "        A = np.identity(height, width)\n",
    "        # Perform ISTA denoising\n",
    "        for i in range(num_iterations):\n",
    "            # Update the denoised image\n",
    "            x = x - step_size* np.transpose(A) *(np.dot(A, x)- img)\n",
    "            x = soft_threshold(x,lambda_val * step_size)\n",
    "        denoised_image = x\n",
    "        denoised_list.append(denoised_image)\n",
    "    return denoised_list\n",
    "\n",
    "def soft_threshold(x, threshold):\n",
    "    return torch.sign(x) * torch.max(torch.abs(x) - threshold, torch.zeros_like(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ista_denoise() got an unexpected keyword argument 'num_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m avg_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m---> 24\u001b[0m     denoised_image \u001b[38;5;241m=\u001b[39m \u001b[43mista_denoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy_example\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     denoised_images_list\u001b[38;5;241m.\u001b[39mappend(denoised_image)\n\u001b[0;32m     27\u001b[0m     clear_images_list\u001b[38;5;241m.\u001b[39mappend(x_clean_example[i,:,:,:])\n",
      "\u001b[1;31mTypeError\u001b[0m: ista_denoise() got an unexpected keyword argument 'num_steps'"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "    \n",
    "# get dataloader\n",
    "train_loader, test_loader = create_dataloaders_noisy_mnist(data_loc, batch_size)\n",
    "    \n",
    "# get some examples\n",
    "training_set = enumerate(train_loader)\n",
    "_, (x_clean, x_noisy, labels) = next(training_set)\n",
    "\n",
    "# %% 1B Show results of denoising\n",
    "# Define constants\n",
    "mu = 0.01\n",
    "K = 100\n",
    "lambda_val = 0.2\n",
    "\n",
    "# Create empty lists\n",
    "denoised_images_list = []\n",
    "clear_images_list = []\n",
    "noisy_images_list = []\n",
    "count = 0\n",
    "avg_mse = 0\n",
    "\n",
    "for i in range(batch_size):\n",
    "    denoised_image = ista_denoise(x_noisy, step_size=mu, num_iterations=K, lambda_val=lambda_val)\n",
    "    denoised_images_list.append(denoised_image)\n",
    "\n",
    "    clear_images_list.append(x_clean_example[i,:,:,:])\n",
    "\n",
    "    noisy_images_list.append(x_noisy_example[i,:,:,:])\n",
    "    \n",
    "    y = x_clean_example[i,:,:,:].reshape(32,32).numpy() \n",
    "    y_pred = denoised_image \n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    count +=1\n",
    "    avg_mse += mse\n",
    "avg_mse /=count\n",
    "print(avg_mse)\n",
    "\n",
    "# %%\n",
    "# Assuming you have a list of noisy images and denoised images\n",
    "clear_images = clear_images_list  # List of clear images (NumPy arrays)\n",
    "denoised_images = denoised_images_list  # List of denoised images (NumPy arrays)\n",
    "noisy_images = noisy_images_list # List of noisy images (NumPy arrays)\n",
    "\n",
    "num_images = len(denoised_images)\n",
    "\n",
    "# Create a figure with subplots for each image\n",
    "fig, axes = plt.subplots(nrows=3, ncols=num_images, figsize=(6 * num_images, 8))\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Get the noisy image and denoised image for the current iteration\n",
    "    noisy_images_np = noisy_images [i].squeeze()\n",
    "    clear_image_np = clear_images[i].squeeze()\n",
    "    denoised_image_np = denoised_images[i].squeeze()\n",
    "\n",
    "    # Plot the denoised image in the first row of subplots\n",
    "    axes[0, i].imshow(noisy_images_np, cmap='gray')\n",
    "    axes[0, i].set_title('Noisy Image')\n",
    "    axes[0, i].axis('off')  \n",
    "\n",
    "    # Plot the denoised image in the first row of subplots\n",
    "    axes[1, i].imshow(denoised_image_np, cmap='gray')\n",
    "    axes[1, i].set_title('Denoised Image')\n",
    "    axes[1, i].axis('off')  \n",
    "\n",
    "    # Plot the clear image in the second row of subplots\n",
    "    axes[2, i].imshow(clear_image_np, cmap='gray')\n",
    "    axes[2, i].set_title('Clear Image')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n",
    "\n",
    "# Save Figure\n",
    "\n",
    "plt.savefig('1B_denoised_ISTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISTA function for denoising\n",
    "def lista_denoise(noisy_image, step_size, num_steps, lambda_val):\n",
    "    # Define the denoising network\n",
    "    denoiser = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "    )\n",
    "\n",
    "    # Scale the noisy image to the range [0, 2] and shift it to the range [-1, 1]\n",
    "    noisy_image = (noisy_image + 1) * 0.5\n",
    "\n",
    "    # Initialize the denoised image\n",
    "    denoised_image = torch.zeros_like(noisy_image)\n",
    "\n",
    "    # Perform ISTA denoising\n",
    "    for i in range(num_steps):\n",
    "        # Compute the gradient of the denoising network\n",
    "        gradient = denoiser(denoised_image)\n",
    "\n",
    "        # Compute the residual\n",
    "        residual = noisy_image - gradient\n",
    "\n",
    "        # Update the denoised image\n",
    "        denoised_image = denoised_image + step_size * residual\n",
    "\n",
    "        # Apply proximal operator (soft-thresholding)\n",
    "        denoised_image = soft_threshold(denoised_image, lambda_val * step_size)\n",
    "\n",
    "    # Scale the denoised image back to the range [-1, 1] and shift it to the range [0, 1]\n",
    "    denoised_image = denoised_image * 2 - 1\n",
    "    denoised_image = torch.clamp(denoised_image, 0, 1)\n",
    "\n",
    "    # Convert the denoised image back to a numpy array\n",
    "    denoised_image = denoised_image.squeeze().squeeze().detach().numpy()\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def soft_threshold(x, threshold):\n",
    "    return torch.sign(x) * torch.max(torch.abs(x) - threshold, torch.zeros_like(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
